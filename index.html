Z<!DOCTYPE HTML>
<HTML>
	<head>
		<title>GW CS Senior Design Andrew Zysk</title>
		<style>
		body {
	background-color: #005A81;
}

h1 {
	margin-left: 80px;
	font-family: "Palatino Linotype", "Book Antiqua", Palatino, serif;
}

h2 {
	font-family: "Cambria";
	margin-left: 30px;
}

p {
	font-family: "Cambria";
}

a:hover {
    color: #2FB8F2;
}

a {
    color: #CBB18B;
    text-decoration: none;
}

#outer_div {
	margin-right: 80px;
	margin-left: 80px;
	background: white;
	border-radius: 8px;
}

#middle_div {
	padding: 30px;
}

#header_div {
	font-family: "Palatino Linotype", "Book Antiqua", Palatino, serif;
	font-size: 30px;
	margin-left: 80px;
	color: white;
}

#inside_div {
	margin-left: 30px;
}

.subheader_div img {
	margin-left: 50px;
	position: relative;
	float: right;
}
		</style>
	</head>
	<body>
		<div id="header_div">
			<p>
			<a href="https://capstone.cs.gwu.edu/">GW CS Senior Design</a> 2017
			</p>
		</div>
		<div id="outer_div">
			<div id="middle_div">
				<div class="subheader_div">
					<h2>Andrew Zysk: Dolphin Image Processor</h2>
					<img src="images/headshot.jpg" width="150">
				</div>
				<div id="inside_div"> 
					<p>
						The Dolphin image processor is an analysis tool for crime scene investigation. Dolphin allows the intended user, a forensic scientist or crime scene investigator, to upload images of crime scene evidence to determine whether an image contains bloodstains, as well as analyze information about the bloodstains. The purpose of Dolphin is to apply a modern image processing and machine learning approach to help crime scene investigators make expedient and accurate analyses.
						Dolphin is implemented using the Play Framework, with Java for the back-end, a MySQL database to store derived data from uploaded samples, and Weka for machine learning.
						When the user uploads an image, they may choose to label the image as blood or notBlood (supervised learning), or prompt the application to label it using the existing training set.
						When an image is uploaded, the application steps through a process to threshold and segment the image. This identifies the "segments" of the image, i.e. contiguous sets of pixels in the image that are sufficiently red. Various attributes are calculated from the segments, such as area, perimeter, convexity, circularity, and average RGB values. These attributes are stored in the database, where they may be used to train the system to recognize blood vs. notBlood.
						The user may build their own training sets in the application by choosing (1) a set of uploaded images for training and (2) a set of segment attributes to be trained on.
					</p> 
					<p>
						<strong>Bio:</strong>
						Andrew Zysk is a graduate of the George Washington University, with a B.S. in Computer Science and a minor in Business Administration.
						In addition to his interests in Image Processing, Computer Vision, and Machine Learning, Andrew has experience working in Project Management and Data Security for a large IT organization.
						
					</p>
					<p>
						<strong>Documentation:</strong> 							
						<ul>
							<li><a href="AndrewZyskProjectSummary.pdf">Project Summary (Writing 1)</a></li>
							<li><a href="AndrewZyskElevatorPitch.pdf">Elevator Pitch, Revised Project Summary (Writing 2)</a></li>
							<li><a href="AndrewZyskCommercialSocietalImpact.pdf">Commercial Opportunity and Societal Impact (Writing 3)</a></li>
							<li><a href="AndrewZyskNSFProposal.pdf">NSF Proposal Complete (Writing 4)</a></li>
							<li><a href="Andrew_Zysk_DesignDocument1.pdf">Design Document</a></li>
							
						</ul>

						<!--
						<iframe 
							width="420" 
							height="315"
							src="FILL-IN YOUR YOUTUBE LINK at end of year and uncomment" 
							frameborder="0" 
							allowfullscreen>
						</iframe>
						!-->
					</p>
				</div>
			</div>
		</div>
	<body>
</HTML>
